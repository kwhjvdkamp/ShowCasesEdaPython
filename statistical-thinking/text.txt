

import numpy as np


==============================

import matplotlib.pyplot as plt
import seaborn as sns
_ = sns.boxplot(x='east_west', y='dem_share', data=df_all_states)
_ = plt.xlabel('region')
_ = plt.ylabel('percent of vote for Obama')
plt.show()


# Specify array of percentiles: percentiles

np.mean(dem_share_PA)

np.median(dem_share_PA)

np.percentile(df_swing['dem_share'], [25,50,75])
percentiles = np.array([2.5, 25, 50, 75, 97.5])

# Compute percentiles: ptiles_vers
ptiles_vers = np.percentile(versicolor_petal_length, percentiles)

# Print the result
print(ptiles_vers)

# Plot the ECDF
_ = plt.plot(x_vers, y_vers, '.')
_ = plt.xlabel('petal length (cm)')
_ = plt.ylabel('ECDF')

# Note that to ensure the Y-axis of the ECDF plot remains between 0 and 1,
# you will need to rescale the percentiles array accordingly,
# in this case, dividing it by 100.
# Overlay percentiles as red diamonds.
_ = plt.plot(ptiles_vers, percentiles/100, marker='D', color='red',
         linestyle='none')

# Show the plot
plt.show()

# !!!standard deviation is the square root of the variance
# !!!the variance is the average of the square distance from the mean!!!
np.var(df)

np.std(df) === np.sqrt(np.var(df))


# Array of differences to mean: differences
differences = versicolor_petal_length - np.mean(versicolor_petal_length)

# Square the differences: diff_sq
diff_sq = differences**2

# Compute the mean square difference: variance_explicit
variance_explicit = np.mean(diff_sq)

# Compute the variance using NumPy: variance_np
variance_np = np.var(versicolor_petal_length)

# Print the results
print(variance_explicit, variance_np)




# scatter plot
_ = plt.plot(total_votes/1000, dem_share, marker='.', linestyle='none')
_ = plt.xlabel('total votes (thousands)')
_ = plt.ylabel('percent of vote for Obama')



greek letter 'rho'(p) = Pearons correlation = ( covariance / (std of x)*(std of y) )  [ unit-less dimensionless]
greek letter 'rho'(p) = ( variability due to codependence / independent variability )

scale: -1 (meaning complete anti-correlation) to 1  (meaning complete correlation)


# Two sets of data x and y,
# np.cov(x, y) returns a 2D array where
# entries [0,1] and [1,0] are the covariances.
# Entry [0,0] is the variance of the data in x, and
# entry [1,1] is the variance of the data in y.
# This 2D output array is called the covariance matrix, since it organizes the self- and covariance

=============================================================

coins: heads or tails
np.random.seed(42)
random_numbers = np.random.random(size=4)
heads = readom_numbers < 0.5
np.sum(heads)

# Seed the random number generator
np.random.seed(42)

# Initialize random numbers which can contain 100000 values: random_numbers
random_numbers = np.empty(100000)

# Generate random numbers by looping over range(100000)
for i in range(100000):
    random_numbers[i] = np.random.random()

# Plot a histogram
_ = plt.hist(random_numbers)

# Show the plot
plt.show()

====Function perform_bernoulli_trials========================================

def perform_bernoulli_trials(n, p):
    """Perform n Bernoulli trials with success probability p
    and return number of successes."""
    # Initialize number of successes: n_success
    # Start with 0 items in the array, it's going to be filled-up
    n_success = np.empty(0)

    # Perform trials
    for i in range(n):

        # Choose random number between zero and one: random_number
        random_number = np.random.random()

        # If less than p, it's a success so add one to n_success
        if random_number < p:
            n_success +=1

    return n_success

# ========================================================


Binomial distribution: the story

The number of R of successes in N Bernoulli trials (coin-flips, dice-throws e.d.) with probability P of success, is Binomial distributed
Explained: the number of R heads in 4 (N) coin flips with probability of 0.5 of heads is Binomial distributed

# ========================================================

EDA		Exploratory Data Analysis
-----------------------------------------------------------------------------------------
(E)CDF	(Empirical) Cumulative Distribution Function  (more effective over PDF because there is no 'binning bias'
PMF  	Probability Mass Function Discrete Uniform  (fliping a coin, throwing a dice, e.d.
PDF		Probability Density Function  (Continuous analog to the PMF)

# ========================================================

import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
x, y = ecdf(samples)
_ = plt.plot(x, y, marker='.', linestyle='none')
plt.margins(0.02)
_ = plt.xlabel('number of successes')
_ = plt.ylabel('CDF')
plt.show()

=====================================

# pre-set: np.random.seed(42)
# Take 10,000 samples out of the binomial distribution: n_defaults
n_defaults = np.random.binomial(100, 0.05, size=10000)

# Compute CDF: x, y
x, y =ecdf(n_defaults)

# Plot the CDF with axis labels
_ = plt.plot(x, y, marker='.', linestyle='none')
plt.margins(0.02)
_ = plt.xlabel('number of defaults out of 100 loans')
_ = plt.ylabel('CDF')

# Show the plot
plt.show()


#  >>> If you know the story, using built-in algorithms to directly sample out of the distribution is much faster.

===========================

# Poisson Process
# Timing of the next event is completely independent of when the previous event had happened



samples = np.random.poisson(6, size=10000)
x, y = ecdf(samples)
_ = plt.plot(x, y, marker='.', linestyle='none')
plt.margins(0.02)
_ = plt.xlabel('number of successes')
_ = plt.ylabel('CDF')
plt.show()


======================================


# Draw 10,000 samples out of Poisson distribution with a mean of 10: samples_poisson
samples_poisson = np.random.poisson(10, size=10000)

# samples_poisson
# >>> array([12,  7, 12, ...,  9, 11,  9])

# len(samples_poisson)
# >>> 10000

# Print the mean and standard deviation
print('Poisson:     ', np.mean(samples_poisson),
                       np.std(samples_poisson))
print('=============================')
# Specify values of n and p to consider for Binomial: n, p
n = [20, 100, 1000]
p = [0.5, 0.1, 0.01]


# Draw 10,000 samples for each n,p pair: samples_binomial
for i in range(3):
    samples_binomial = np.random.binomial(n[i], p[i], size=10000)
    # Print results
    print('n =', n[i], ' | Binom (mean): ', np.mean(samples_binomial), ', (std)', np.std(samples_binomial))

# Explanation
# The means are all about the same, which can be shown to be true by doing some pen-and-paper work. The standard deviation of the
# Binomial distribution gets closer and closer to that of the Poisson distribution as the probability p gets lower and lower.


# In baseball, a no-hitter is a game in which a pitcher does not allow the other team to get a hit. This is a rare event, and since
# the beginning of the so-called modern era of baseball (starting in 1901), there have only been 251 (low p) of them through the 2015 season # in over 200,000 games (high n). The ECDF of the number of no-hitters in a season is shown to the right.
# Which probability distribution would be appropriate to describe the number of no-hitters we would expect in a given season?

# When we have rare events (low p, high n), the Binomial distribution is Poisson.
# This has a single parameter, the mean number of successes per time interval, in our case the mean number of no-hitters per season.

# ===============================

#1990 and 2015 featured the most no-hitters of any season of baseball (there were seven).
# Given that there are on average 251/115 no-hitters per season, what is the probability of having seven or more in a season?
# Draw 10,000 samples out of Poisson distribution: n_nohitters
size = 10000
n_nohitters = np.random.poisson((251/115), size=size)

# Compute number of samples that are seven or greater: n_large
n_large = np.sum(n_nohitters >= 7)

# Compute probability of getting seven or more: p_large
p_large = n_large / size

# Print the result
print('Probability of seven or more no-hitters:', p_large)



IMPORTANT
=======================================================================
PARAMETER					CALCULATED FROM Data
-----------------------------------------------------------------------
MEAN			|	NOT		|	Mean
of a NORMAL 		|	EQUAL		|	computed
distribution		|	WITH		|	from data
-----------------------------------------------------------------------
ST.DEV			|	NOT		|	Standard deviation
of a NORMAL 		|	EQUAL		|	computed
distribution		|	WITH		|	from data



# ==========================================================

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

mean = np.mean(michelson_speed_of_light)
std = np.std(michelson_speed_of_light)

samples = np.random.normal(mean, std, size=10000)
x, y = ecdf(michelson_speed_of_light)
x_theor, y_theor = ecdf(samples)

sns.set()
# two plots
_= plt.plot(x_theor, y_theor)
_= plt.plot(x, y, marker='.', linestyle='none')
_= plt.xlabel('speed of light (km/s)')
_= plt.ylabel('CDF')
plt.show()


# =====continue============

Normal CDF

# Generate CDFs
x_std1, y_std1 = ecdf(samples_std1)
x_std3, y_std3 = ecdf(samples_std3)
x_std10, y_std10 = ecdf(samples_std10)

# Plot CDFs
_ = plt.plot(x_std1, y_std1, marker='.', linestyle='none')
_ = plt.plot(x_std3, y_std3, marker='.', linestyle='none')
_ = plt.plot(x_std10, y_std10, marker='.', linestyle='none')

plt.margins(0.02)

_ = plt.xlabel('std')
_ = plt.ylabel('CDF\'s')

# Make a legend and show the plot
_ = plt.legend(('std = 1', 'std = 3', 'std = 10'), loc='lower right')
plt.show()

# Graphical explanation:
# The CDFs all pass through the mean at the 50th percentile;
# the mean and median of a Normal distribution are equal.
# The width of the CDF varies with the standard deviation.


# ========================================================

# Compute mean and standard deviation: mu, sigma
mu = np.mean(belmont_no_outliers)
sigma = np.std(belmont_no_outliers)

# Sample out of a normal distribution with this mu and sigma: samples
samples = np.random.normal(mu, sigma, size=10000)

# Get the CDF of the samples and of the data
x_theor, y_theor = ecdf(samples)	# Blue line
x, y = ecdf(belmont_no_outliers)	# Orange dots

# Plot the CDFs and show the plot
_ = plt.plot(x_theor, y_theor)
_ = plt.plot(x, y, marker='.', linestyle='none')
_ = plt.xlabel('Belmont winning time (sec.)')
_ = plt.ylabel('CDF')
plt.show()




# Graphical explanation:
# The theoretical CDF and the ECDF of the data suggest that the
# winning Belmont times are, indeed, Normally distributed.


# ========================================

# Take a million samples out of the Normal distribution: samples
samples = np.random.normal(mu, sigma, size=1000000)

# Compute the  FRACTION (not the total) that are faster than 144 seconds: prob
# 144 seconds from the fastest run by horse Secretariat
prob = np.sum(samples < 144) / 1000000

# Print the result
print('Probability of besting Secretariat:', prob)

# <script.py> output: Probability of besting Secretariat: 0.000635

# We had to take a million samples because the probability of a fast time is very low
# and we had to be sure to sample enough.
# We get that there is only a 0.06% chance of a horse running the Belmont as fast as Secretariat.


# ==video=================================

# Exponential inter-incident times

mean = np.mean(inter_times)
samples = np.random.exponential(mean, size = 10000)
x, y = ecdf(inter_times)
x_theor, y_theor = ecdf(samples)
_=plt.plot(x_theor, y_theor)
_=plt.plot(x, y, marker='.', linestyle='none')
_=plt.xlabel('time (days)')
_=plt.ylabel('CDF')
plt.show()

# ==Function successive_poisson=====================================================

def successive_poisson(tau1, tau2, size=1):
    """Compute time for arrival of 2 successive Poisson processes."""
    # Draw samples out of first exponential distribution: t1
    t1 = np.random.exponential(tau1, size = 1)

    # Draw samples out of second exponential distribution: t2
    t2 = np.random.exponential(tau2, size = 1)

    return t1 + t2

# =================================================================================


# =====Part II =====================================================================

# Seed random number generator
np.random.seed(42)

# Compute mean no-hitter time: tau
tau = np.mean(nohitter_times)

# Draw out of an exponential distribution with parameter tau: inter_nohitter_time
inter_nohitter_time = np.random.exponential(tau, 100000)

# Plot the PDF and label axes
_ = plt.hist(inter_nohitter_time,
             density=True, histtype='step', bins=50)
_ = plt.xlabel('Games between no-hitters')
_ = plt.ylabel('PDF')

# Show the plot
plt.show()

# We see the typical shape of the Exponential distribution, going from a maximum at 0 and decaying to the right


# ======================================================


# Create an ECDF from real data: x, y
x, y = ecdf(nohitter_times)

# Create a CDF from theoretical samples: x_theor, y_theor
x_theor, y_theor = ecdf(inter_nohitter_time)

# Overlay the plots
plt.plot(x_theor, y_theor)
plt.plot(x, y, marker='.', linestyle='none')

# Margins and axis labels
plt.margins(0.02)
plt.xlabel('Games between no-hitters')
plt.ylabel('CDF')

# Show the plot
plt.show()


# =====================================================


# Create an ECDF from real data: x, y  [previous task}
x, y = ecdf(nohitter_times)

# Create a CDF from theoretical samples: x_theor, y_theor
x_theor, y_theor = ecdf(inter_nohitter_time)

# Overlay the plots
plt.plot(x_theor, y_theor)
plt.plot(x, y, marker='.', linestyle='none')

# Margins and axis labels
plt.margins(0.02)
plt.xlabel('Games between no-hitters')
plt.ylabel('CDF')

# Show the plot
plt.show()

# It looks like no-hitters in the modern era of Major League Baseball are Exponentially distributed.
# Based on the story of the Exponential distribution, this suggests that they are a random process;
# when a no-hitter will happen is independent of when the last no-hitter was.

# ========================================================================




With exercise: How often do we get no-hitters? is proved [with a PDF]:

# Result
# Typical shape of the Exponential distribution, it's going from a maximum at 0 and decaying to the right

Next exercise: Do the data follow our story? is shown [with (E)CDF]:

# Result
# Overlay of the theoretical CDF with the ECDF from the real data is verified
that the Exponential distribution describes the observed data

# Learning effect
Based on the story of the Exponential distribution,
1) the theoretical presentation clearly follows the real data and 2) they both clearly present exponential presentations:
it may be concluded the happening of a no-hitter-game is an independent occurence compared to the occurence of another no-hitter-game  (and therefore both are random processes)

# ========================================================================

				X,        Y	      Z
slope, intercept = np.polyfit(total_votes, dem_share, 1)
X	dataset
Y	dataset
Z = is the degree of polynomial you which to fit
lineair functions = 1

Definition: literacy (opposite= illiteracy)
Total number of literate persons in a given age group, expressed as a percentage of the
total population in that age group.
The adult literacy rate measures literacy among persons aged 15 years and above,
and the youth literacy rate measures literacy among persons aged 15 to 24 years.


# =============================================================

# Plot the illiteracy rate versus fertility
_ = plt.plot(illiteracy, fertility, marker='.', linestyle='none')

# Set the margins and label axes
plt.margins(0.02)
_ = plt.xlabel('percent illiterate')
_ = plt.ylabel('fertility')

# Show the plot
plt.show()

# ====Function pearson_r ====================================================

# Show the Pearson correlation coefficient
def pearson_r(x, y):
    """Compute Pearson correlation coefficient between two arrays."""
    # Compute correlation matrix: corr_mat
    corr_mat = np.corrcoef(x,y)

    # Return entry [0,1]
    return corr_mat[0,1]

print(pearson_r(illiteracy, fertility))

# The correlation between illiteracy and fertility by eye,
# and by the substantial Pearson correlation coefficient of 0.8.
# It is difficult to resolve in the scatter plot, but there are many points around
# near-zero illiteracy and about 1.8 children/woman.

# ============================================================================

# Asumption: fertility is a linear function of the female il-literacy (ongeletterdheid) rate
# Plot the illiteracy rate versus fertility
_ = plt.plot(illiteracy, fertility, marker='.', linestyle='none')
plt.margins(0.02)
_ = plt.xlabel('percent illiterate')
_ = plt.ylabel('fertility')

# Perform a linear regression using np.polyfit(): a, b
# slope(a), intercept(b)
a, b = np.polyfit(illiteracy, fertility, 1)

# Print the results to the screen
print('slope =', a, 'children per woman / percent illiterate')
print('intercept =', b, 'children per woman')

# Make theoretical line to plot
# f=ai+b, where a is the slope and b is the intercept
# Length of the X-Axis from 0 to 100 (%)
x = np.array([0, 100])
y = a * x + b

# Add regression line to your plot
_ = plt.plot(x, y)
_ = plt.xlabel('percent illiterate')
_ = plt.ylabel('fertility')

# Draw the plot
plt.show()
slope = 0.04979854809063423 children per woman / percent illiterate
intercept = 1.888050610636557 children per woman

# ==========================================================
# Machting with a lot of slopes sampling with the real-slope (slope ~ 0.0498)
# The function np.polyfit() is used to get your regression parameters which finds the optimal slope and intercept.
# It is optimizing the sum of the squares of the residuals, also known as RSS (for residual sum of squares).
# Residual is vertical distance of a point from the regression line can negative (points below) and positive (points above)

# Plot the function that is being optimized, the RSS, versus the slope parameter 'a'

# Specify slopes to consider: a_vals
a_vals = np.linspace(0, 0.1, 200)

# Initialize sum of square of residuals: rss
rss = np.empty_like(a_vals)

# Compute sum of square of residuals for each value of a_vals
# Variable a (=slope)
# Variable b (=intercept:  1.888050610636557 children per woman)
# which is computed in the last exercise is
# already in your namespace
for i, a in enumerate(a_vals):
    rss[i] = np.sum((fertility - a*illiteracy - b)**2)

# Plot the RSS
plt.plot(a_vals, rss, '-')
plt.xlabel('slope (children per woman / percent illiterate)')
plt.ylabel('sum of square of residuals')

plt.show()

# Explanation graph: omgekeerde dal-parabool
# Minimum on the plot (x-coordinate), that is the value of the slope that gives the
# minimum sum of the square of the residuals,
# is the same value you got when performing the regression

# Needs proof to calculate the 'top' (actual dal-point) of this parabolic (dal-parabool) presentation
# Unknown: parabolic function something linke y = (+/-)ax**2 + bx + c  (note (+) is dal-parabool, (-) is berg-...)

# x-coordinate is de slope van de regression-line matches (on eyes) with the real-slope calculated (slope ~ 0.0498)


# =========================================

#  x & y are array already stored
# Perform linear regression: a, b
a, b = np.polyfit(x, y, 1)

# Print the slope and intercept
print(a, b)

# Generate theoretical x and y data: x_theor, y_theor
x_theor = np.array([3, 15])
y_theor = a * x_theor + b     # function lineair line (y=a*x+b)

# Plot the Anscombe data and theoretical line
_ = plt.plot(x, y, marker='.', linestyle='none')
_ = plt.plot(x_theor, y_theor)

# Label the axes
plt.xlabel('x')
plt.ylabel('y')

# Show the plot
plt.show()


# ====================================

# The data are stored in lists;
# anscombe_x = [x1, x2, x3, x4] and
# anscombe_y = [y1, y2, y3, y4],
# where, for example,
# x2 and y2 are the x and y values for the second Anscombe data set,
# and so on

# Iterate through x,y pairs
for x, y in zip(anscombe_x, anscombe_y):
    # Lineair regression: so 'z' is 1
    # Compute the slope and intercept: a, b
    a, b = np.polyfit(x, y, 1)

    # Print the result
    print('slope:', a, 'intercept:', b)





#+++++++++++++++++++++++++++
# Bootstrapping: The use of resampled data to perfrom statistical inference
# A [Bootstrap Sample] is a resampled array of the data
# A [Bootstrap Replicate] is the value of the summary statistic computed from the [Bootstrap Sample]
# >>> Generating [Bootstrap Sample] and compute the [Bootstrap Replicate]


# Rainfall data measured at the Sheffield Weather Station in the UK from 1883 to 2015. so len(rainfall) = 133
# Note this is THE size of the rainfall array
# Drawing 50 samples, so looping 50 times
# =================================
for i in range(50):
    # Generate bootstrap sample: bs_sample
    bs_sample = np.random.choice(rainfall, size=len(rainfall))

    # Compute and plot ECDF from bootstrap sample
    x, y = ecdf(bs_sample)
    _ = plt.plot(x, y, marker='.', linestyle='none',
                 color='gray', alpha=0.1)

# ===========================================

# Compute and plot ECDF from original data
x, y = ecdf(rainfall)
_ = plt.plot(x, y, marker='.')

# Make margins and label axes
plt.margins(0.02)
_ = plt.xlabel('yearly rainfall (mm)')
_ = plt.ylabel('ECDF')

# Show the plot
plt.show()



# ===Function bootstrap_replicate_1d ============================================

def bootstrap_replicate_1d(data, func):
	"""Generate bootstrap replicate of 10 data"""
	bs_sample = np.random.choice(data, len(data))
	return func(bs_sample)

# For example
# print (bootstrap_replicate_1d(michelson_speed_of_light, np.mean) )
# Prints the 'mean' of the 'bs_sample'
# To do this many times: for-loop

# Need a basket: bs_replicates = np.empty(10000) (can contain 10000 values)
for i in range(10000):
    # Generate bootstrap sample containing 10000 bs_replicates
    bs_replicates[i] = bootstrap_replicate_1d((michelson_speed_of_light, np.mean)

# Creating a histogram [PDF = Probability Distribution Function]
_ = plt.hist(bs_replicates, density=True, bins=30)
_ = plt.xlabel('Mean speed of light (km/s)')
_ = plt.ylabel('PDF')

# Show the plot
plt.show()

# Normed=True means the height of the bars are set in such a way that the 'total area' of the bars is EQUAL to 1
# This is done so that the histogram approximates a probability density function. This is normalization!
# The area under de PDF gives a probability

# Now we can think 'Probabilistically'

# ===Function (Parent) draw_bs_reps > Function (Child) bootstrap_replicate_1d======

# ===BEGIN Work Horse=I==IMPORTANT======================

## This function is called many times as far as the given size concerns
def bootstrap_replicate_1d(data, func):
    """Generate bootstrap replicate of 1D data."""
    bs_sample = np.random.choice(data, len(data))
    return func(bs_sample)

# Generate many bootstrap replicates from a data set with a typical function
def draw_bs_reps(data, func, size=1):
    """Draw bootstrap replicates"""
    # Initialize array of replicates: bs_replicates
    bs_replicates = np.empty(size)

    # Generate replicates
    for i in range(size):
        bs_replicates[i] = bootstrap_replicate_1d(data, func)

    return bs_replicates

# ===END Work Horse=I==IMPORTANT=======================

# ======================================================

# Dataset: rainfall measurements from 1883 to 2015
# Take 10,000 bootstrap replicates of the mean: bs_replicates
bs_replicates = draw_bs_reps(rainfall, np.mean, 10000)

# Compute and print SEM (standard error of the mean) of the actual data (rainfall)
sem = np.std(rainfall) / np.sqrt(len(rainfall))
print(sem)

# Compute and print standard deviation of bootstrap replicates
bs_std = np.std(bs_replicates)
print(bs_std)

# Make a histogram of the results
_ = plt.hist(bs_replicates, bins=50, density=True)
_ = plt.xlabel('mean annual rainfall (mm)')
_ = plt.ylabel('PDF')

# Show the plot
plt.show()


# =========================================

# Generate 10,000 bootstrap replicates of the variance: bs_replicates
# using [Work Horse]
bs_replicates = draw_bs_reps(rainfall, np.var, 10000)

# Put the variance in units of square centimeters
bs_replicates = bs_replicates / 100

# Compute the 95% confidence interval: conf_int
conf_int = np.percentile(bs_replicates, [2.5, 97.5])

# Print the confidence interval
print('95% confidence interval =', conf_int, 'rain fall')
# 95% confidence interval = [114.87926838 179.45385568] rain fall

# Make a histogram of the results
_ = plt.hist(bs_replicates, density=True, bins=50)
_ = plt.xlabel('variance of annual rainfall (sq. cm)')
_ = plt.ylabel('PDF')

conf_int = np.percentile(bs_replicates, [2.5, 97.5])
print(conf_int)

# Show the plot
plt.show()


# Explanantion The plot shows 'not normally distribution'.
# The plot as it has a longer tail to the right.
# Note that you can also compute a confidence interval on the variance,
# or any other statistic,
# using np.percentile() with your bootstrap replicates.


# ======================================================

# Draw bootstrap replicates of the mean no-hitter time (equal to tau): bs_replicates
bs_replicates = draw_bs_reps(nohitter_times, np.mean, 10000)

# Compute the 95% confidence interval: conf_int
conf_int = np.percentile(bs_replicates, [2.5, 97.5])

# Print the confidence interval
print('95% confidence interval =', conf_int, 'games')
# 95% confidence interval = [660.67280876 871.63077689] games

# Plot the histogram of the replicates
_ = plt.hist(bs_replicates, bins=50, density=True)
_ = plt.xlabel(r'$\tau$ (games)')
_ = plt.ylabel('PDF')

# Show the plot
plt.show()


#==========================================================================

# ===Function draw_bs_pairs_linreg===============================================
# note: estimation of 'slope' and 'intercept': these are parametric estimates
# computing confidence intervals

# Defining a function to do resampling op pairs, pairs are estimate slopes and intercepts
# So actually resample of all possible lineair regressions by slopes en intercepts

def draw_bs_pairs_linreg(x, y, size=1):
    """Perform pairs bootstrap for linear regression."""

    # Set up array of indices to sample from: inds
    # Length of the range should be as long as the data length
    # in this case the length of data stored in 'x' of 'y'
    inds = np.arange(len(x))

    # Initialize replicates: bs_slope_reps, bs_intercept_reps
    bs_slope_reps = np.empty(size)
    bs_intercept_reps = np.empty(size)

    # Generate replicates
    # Once again the size in the range is the amount of samples
    for i in range(size):
        bs_inds = np.random.choice(inds, size=len(inds))
        bs_x, bs_y = x[bs_inds], y[bs_inds]
        bs_slope_reps[i], bs_intercept_reps[i] = np.polyfit(bs_x, bs_y, 1)

    return bs_slope_reps, bs_intercept_reps
#==========================================================================



# ======================================

# using the draw_bs_pairs_linreg-function to take 1000 bootstrap replicates
# of the slope and intercept. The x-axis data is illiteracy and y-axis data is fertility

# Generate replicates of slope and intercept using pairs bootstrap
bs_slope_reps, bs_intercept_reps = draw_bs_pairs_linreg(illiteracy, fertility, 1000)

# Compute and print 95% CI for slope
print(np.percentile(bs_slope_reps, [2.5, 97.5]))

# Plot the histogram
_ = plt.hist(bs_slope_reps, bins=50, density=True)
_ = plt.xlabel('slope')
_ = plt.ylabel('PDF')
plt.show()

# A nice way to visualize the variability we might expect in a linear regression is
# to plot the line you would get from each bootstrap replicate of the slope and intercept.
# Do this for the first 100 of your bootstrap replicates of the
# slope and intercept (stored in arrays 'bs_slope_reps' and 'bs_intercept_reps').

# Generate array of x-values for bootstrap lines: x
x = np.array([0, 100])

# Plot the bootstrap lines
for i in range(100):
    # regression equation: y = a*x + b
    # a is bs_slope_reps[i] and b is bs_intercept_reps[i]
    _ = plt.plot(x,
                 bs_slope_reps[i]*x + bs_intercept_reps[i],
                 linewidth=0.5, alpha=0.2, color='red')

# Plot the data
_ = plt.plot(illiteracy, fertility, marker='.', linestyle='none')

# Label axes, set the margins, and show the plot
_ = plt.xlabel('illiteracy')
_ = plt.ylabel('fertility')
plt.margins(0.02)
plt.show()


# ====NULL hypothesis==========================================================
#===Function permutation_sample================================================

#  permutation sample
# Permutation sampling is a great way to simulate the hypothesis that
# two variables have identical probability distributions.

def permutation_sample(data1, data2):
    """Generate a permutation sample from two data sets."""

    # Concatenate the data sets: data
    # data = np.concatenate([data1, data2])
    data = np.concatenate((data1, data2))

    # Permute the concatenated array: permuted_data
    permuted_data = np.random.permutation(data)

    # Split the permuted array into two: perm_sample_1, perm_sample_2
    # a[start:stop]  # items start through stop-1
    # a[start:]      # items start through the rest of the array
    # a[:stop]       # items from the beginning through stop-1
    # a[:]           # a copy of the whole array
    # because data is a concatenation of first data with second data2
    # from the beginning to len(data1) write as ':len(data1)'
    # next, 'len(data1):' means the rest of array actually len(data2)
    perm_sample_1 = permuted_data[:len(data1)]
    perm_sample_2 = permuted_data[len(data1):]

    return perm_sample_1, perm_sample_2
#===============================================================================

# Using function permuation_sample(data1, data2)
# Using a for-loop to generate 50 permutation samples,
# compute their experimental ECDFs, compared those with the real ECDF for datasets 'rain-juni' and 'rain-nov'
# and plot them.
for i in range(50):
    # Generate permutation samples
    perm_sample_1, perm_sample_2 = permutation_sample(rain_june, rain_november)

    # Compute ECDFs
    x_1, y_1 = ecdf(perm_sample_1)
    x_2, y_2 = ecdf(perm_sample_2)

    # Plot ECDFs of permutation sample
    _ = plt.plot(x_1, y_1, marker='.', linestyle='none',
                 color='red', alpha=0.02)
    _ = plt.plot(x_2, y_2, marker='.', linestyle='none',
                 color='blue', alpha=0.02)

# Create and plot ECDFs from original data
x_1, y_1 = ecdf(rain_june)
x_2, y_2 = ecdf(rain_november)
_ = plt.plot(x_1, y_1, marker='.', linestyle='none', color='red')
_ = plt.plot(x_2, y_2, marker='.', linestyle='none', color='blue')

# Label axes, set margin, and show plot
plt.margins(0.02)
_ = plt.xlabel('monthly rainfall (mm)')
_ = plt.ylabel('ECDF')
plt.show()


# Graph explanation
# Notice that the permutation samples ECDFs overlap and give a purple haze.
# Whereas rain_juni (red) and rain-november (blue) do not overlap with the  permutation samples 'purple haze'
# This suggests that the hypothesis is not commensurate with the data.
# ?? What was the hypothesis ??

June and November rainfall are not identically distributed.


# Important

Determination of the 'p-value', is exactly what is means, that the probability of obtaining a value of test statistics
that is at least as extreme as what is observed, UNDER the assumption that the NULL hypothesis is TRUE
>> It does NOT describe the probability that the null hypothesis is TRUE

# Remember Statistical significance (low p-values) and practical significance,
# whether or not the difference of the data from the null hypothesis matters for practical considerations are two different things

# =======================================================

# Permutation replicate is a single value of a statistic computed from a permutation sample

# ===BEGIN Work Horse=II==IMPORTANT=================================================
#===========Function draw_perm_reps==================================================
def draw_perm_reps(data_1, data_2, func, size=1):
    """Generate multiple permutation replicates"""
    # Initialize array of replicates: perm_replicates
    perm_replicates = np.empty(size)

    for i in range(size):
        # Generate permutation sample
        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)

        # Compute the test statistic
        perm_replicates[i] = func(perm_sample_1, perm_sample_2)

    return perm_replicates

# ===END Work Horse=II==IMPORTANT=======================================================
# =================================================================================

# Experiment with South American horned frogs.
# In front of frogs was held a plate connected to a force transducer,
# along with a bait fly, in front of them.
# I was measured the impact force and adhesive force of the frog's tongue when it struck the target.
# Frog A is an adult and Frog B is a juvenile.
# The researchers measured the impact force of 20 strikes for each frog.
# The hypothesis is tested that the two frogs, adult and juvenile, have the same distribution of impact forces.
# It is important to do EDA first!
# 1) Let's make a bee swarm plot for the data.
# Date is stored in a Pandas data frame, df, where
# column ID is the identity of the frog and column impact_force is the impact force in Newtons (N).

# Make bee swarm plot
_ = sns.swarmplot(x='ID', y='impact_force', data=df)

# Label axes
_ = plt.xlabel('frog')
_ = plt.ylabel('impact force (N)')

# Show the plot
plt.show()

# Explaination graph
# It does not look like they come from the same distribution.
# Frog A, the adult, has three or four very hard strikes, and
# Frog B, the juvenile, has a couple weak ones.
# However, it is very likely that with only 20 samples,
# it might be too difficult to tell, if they have difference distributions,
# so furhter testing on the hypothesis is needed
# 2) Permutation test

# ============================================================

# The average strike force of Frog A was 0.71 Newtons (N), and
# that of Frog B was 0.42 N
# meaning a difference of 0.29 N.
# It is possible, the frogs strike with the same force and this observed difference was by chance.
# Compute the probability of getting at least a 0.29 N difference in mean strike force
# under the hypothesis that the distributions of the strike forces for the two frogs are identical.

#===Function diff_of_means=========================================

def diff_of_means(data_1, data_2):
    """Difference in means of two arrays."""

    # The difference of means of data_1, data_2: diff
    diff = np.mean(data_1) - np.mean(data_2)

    return diff
#=========================================================================

# Compute difference of mean impact force from the experiment: empirical_diff_means
# on the real datasets: 'force_a' and 'force_b'
empirical_diff_means = diff_of_means(force_a, force_b)
print('empirical_diff_in_means_of_the_two_datasets: ', empirical_diff_means)

# Draw 10,000 permutation replicates: perm_replicates => TESTING the hypothesis
# with 'Work Horse II', for this reason the function 'diff_of_means' has been setup

samples= 10000
perm_replicates = draw_perm_reps(force_a, force_b,
                                 diff_of_means, size=samples)

print('List of', samples, ' samples: ', perm_replicates)

# Compute p-value: p
p = np.sum(perm_replicates >= empirical_diff_means) / len(perm_replicates)

# Print the result
print('p-value =', p)
Output: p-value = 0.0063


# Explanation
# The p-value tells you that there is about a 0.6% chance that you would get the
# difference of means observed in the experiment if frogs were exactly the same.
# A p-value below 0.01 is typically said to be "statistically significant,"
# but: WARNING! WARNING! WARNING!
# You have computed a p-value; it is a number.
# I encourage you not to distill it to a [Yes]-or-[NO] phrase.
# p = 0.006 and p = 0.000000006 are both said to be
# "statistically significant," but they are definitely not the same!

# ========================================================


# Description
# Another juvenile frog was studied, Frog C, and you want to see if Frog B and Frog C
# have similar impact forces. Unfortunately, you do not have Frog C's impact forces available,
# but you know they have a mean of 0.55 N.
# Because you don't have the original data, 1) you cannot do a permutation test, 2) and you
# cannot assess the hypothesis that the forces from Frog B and Frog C come from the same distribution.
# You will therefore test another, less restrictive hypothesis:
# The mean strike force of Frog B is equal to that of Frog C.

# To set up the bootstrap hypothesis test, you will take the mean as our test statistic.
# Remember, your goal is to calculate the probability of getting a mean impact force less than or equal
# to what was observed for Frog B if the hypothesis that the true mean of Frog B's impact forces is equal
# to that of Frog C is true.
# You first translate all of the data of Frog B such that the mean is 0.55 N.
# This involves adding the mean force of Frog C and subtracting the mean force of Frog B from each measurement
# of Frog B. This leaves other properties of Frog B's distribution, such as the variance, unchanged.

# Make an array of translated impact forces: translated_force_b
print('Mean of the shifted array: ',
round(np.mean(np.add(force_b, (0.55 - np.mean(force_b))).tolist()), 2), 'N ===', 0.55, 'N')
translated_force_b = np.add(force_b, (0.55 - np.mean(force_b))).tolist()

# Take bootstrap replicates of Frog B's translated impact forces: bs_replicates
bs_replicates = draw_bs_reps(translated_force_b, np.mean, 10000)

# Compute fraction of replicates that are less than the observed Frog B force: p
p = np.sum(bs_replicates <= np.mean(force_b)) / 10000

# Print the p-value
print('p = ', p)
<script.py> output:
Mean of the shifted array:  0.55 N === 0.55 N
p =  0.0046

#Description
# Exercise

A two-sample bootstrap hypothesis test for difference of means
We now want to test the hypothesis that Frog A and Frog B have the same mean impact force,
# but not necessarily the same distribution, which is also impossible with a permutation test.

# To do the two-sample bootstrap test, we shift both arrays to have the same mean,
# since we are simulating the hypothesis that their means are, in fact, equal.
# We then draw bootstrap samples out of the shifted arrays and compute the difference in means.
# This constitutes a bootstrap replicate, and we generate many of them. The p-value is the fraction
# of replicates with a difference in means greater than or equal to what was observed.

# The objects 'forces_concat' and 'empirical_diff_means' are already in your namespace.

# Compute mean of all forces: mean_force
mean_force = np.mean(forces_concat)

# Generate shifted arrays
force_a_shifted = force_a - np.mean(force_a) + mean_force
force_b_shifted = force_b - np.mean(force_b) + mean_force

samples = 10000
# Compute 10,000 bootstrap replicates from shifted arrays
bs_replicates_a = draw_bs_reps(force_a_shifted, np.mean, samples)
bs_replicates_b = draw_bs_reps(force_b_shifted, np.mean, samples)

print(bs_replicates_a)
print(bs_replicates_b)

# Get replicates of difference of means: bs_replicates
bs_replicates = bs_replicates_a - bs_replicates_b

# Compute and print p-value: p
p = np.sum(bs_replicates >= empirical_diff_means) / len(bs_replicates)
print('p-value =', p)

<script.py> output:  p-value = 0.0043

# Explanation
# You got a similar result as when you did the permutation test.
# Nonetheless, remember that it is important to carefully think about what question you want to ask.
# Are you only interested in the mean impact force,
# or in the distribution of impact forces?


[I] - [Permutation test] > Frog A (adult) <-> Frog B (juvenile)
p-value = 0.0063
[II] - [A one-sample bootstrap hypothesis test] > Frog B (juvenile) <-> Frog C (juvenile)
p =  0.0046
[III] - [A two-sample bootstrap hypothesis test for difference of means] > Frog A (adult) <-> Frog B (juvenile)
p-value = 0.0043


# ===A/B Testing=Function diff_frac====================================


def diff_frac(data_A, data_B)
	frac_A = np.sum(data_A / len(data_A)
	frac_A = np.sum(data_B / len(data_B)
	return frac_B - frac_A

diff_frac_obs = diff_frac(clickthough_A, clickthrough_B)

perm_replicates = np.empty(10000)
for i in range(10000)
	perm_replicates[i] = permutation_replicate (clickthrough_A, clickthrough_B, diff_frac)

p = np.sum(perm_replicates >= diff_frac_obs) / 10000


# ======================================================================


# Construct arrays of data: dems, reps
dems = np.array([True] * 153 + [False] * 91)
reps = np.array([True] * 136 + [False] * 35)

print(np.sum(dems))
print(len(dems))
mean_dems_yea = np.sum(dems)/len(dems)
print(mean_dems_yea)

def frac_yea_dems(dems, reps):
    """Compute fraction of Democrat yea votes."""
    frac = np.sum(dems) / len(dems)
    return frac

print (frac_yea_dems(dems, reps))
# Acquire permutation samples: perm_replicates
perm_replicates = draw_perm_reps(dems, reps, frac_yea_dems, 10000)

# Compute and print p-value: p
p = np.sum(perm_replicates <= mean_dems_yea) / len(perm_replicates)
print('p-value =', p)
<script.py> output:
    153
    244
    0.6270491803278688
    0.6270491803278688
    p-value = 0.0002


# This small p-value suggests that party identity had a lot to do with the voting.
# Importantly, the South had a higher fraction of Democrat representatives,
# and consequently also a more racist bias.


# ========================================================


# Compute the observed difference in mean inter-no-hitter times: nht_diff_obs
nht_diff_obs = diff_of_means(nht_dead, nht_live)

# Acquire 10,000 permutation replicates of difference in mean no-hitter time: perm_replicates
samples= 10000
perm_replicates = draw_perm_reps(nht_dead, nht_live,
                                 diff_of_means, size=samples)

# Compute and print the p-value: p

p = np.sum(perm_replicates <= nht_diff_obs) / len(perm_replicates)
print('p-val =', p)
<script.py> output:
    p-val = 0.0001

# Explanation
# Your p-value is 0.0001, which means that only one out of your 10,000 replicates
# had a result as extreme as the actual difference between the dead ball and live ball eras.
# This suggests strong statistical significance.
# Watch out, though, you could very well have gotten zero replicates that were as extreme as the observed value.
# This just means that the p-value is quite small, almost certainly smaller than 0.001.


# =====================================================

# Compute observed correlation: r_obs
r_obs = pearson_r(illiteracy, fertility)
print(r_obs)

# Initialize permutation replicates: perm_replicates
perm_replicates = np.empty(10000)

# Draw replicates
for i in range(10000):
    # Permute illiteracy measurments: illiteracy_permuted
    illiteracy_permuted = np.random.permutation(illiteracy)

    # Compute Pearson correlation
    perm_replicates[i] = pearson_r(illiteracy_permuted, fertility)

# Compute p-value: p
p = np.sum(perm_replicates >= r_obs) / len(perm_replicates)

print('p-val =', p)
<script.py> output:
    0.8041324026815344
    p-val = 0.0

# You got a p-value of zero.
# In hacker statistics, this means that your p-value is very low, since you never got a single replicate
# in the 10,000 you took that had a Pearson correlation greater than the observed one.
# You could try increasing the number of replicates you take to continue to move the upper bound on
# your p-value lower and lower.


# ===================================================

# Compute x,y values for ECDFs
x_control, y_control = ecdf(control)
x_treated, y_treated = ecdf(treated)

# Plot the ECDFs
plt.plot(x_control, y_control, marker='.', linestyle='none')
plt.plot(x_treated, y_treated, marker='.', linestyle='none')

# Set the margins
plt.margins(0.02)

# Add a legend
plt.legend(('control', 'treated'), loc='lower right')

# Label axes and show plot
plt.xlabel('millions of alive sperm per mL')
plt.ylabel('ECDF')
plt.show()

# Explanation
# The ECDFs show a pretty clear difference between the treatment and control; treated bees have fewer alive sperm.
# Let's now do a hypothesis test in the next exercise.



# =====================================

# Compute the difference in mean sperm count: diff_means
diff_means = diff_of_means(control, treated)

# Compute mean of pooled data: mean_count
mean_count = np.mean(np.concatenate((control, treated)))

# Generate shifted data sets
control_shifted = control - np.mean(control) + mean_count
treated_shifted = treated - np.mean(treated) + mean_count

# Generate bootstrap replicates
bs_reps_control = draw_bs_reps(control_shifted, np.mean, size=10000)
bs_reps_treated = draw_bs_reps(treated_shifted, np.mean, size=10000)

# Get replicates of difference of means: bs_replicates
bs_replicates = bs_reps_control - bs_reps_treated

# Compute and print p-value: p
p = np.sum(bs_replicates >= np.mean(control) - np.mean(treated)) / len(bs_replicates)
print('p-value =', p)

output: p-value = 0.0

# Explanation
# The p-value is small, most likely less than 0.0001, since you never saw a bootstrap replicated
# with a difference of means at least as extreme as what was observed.
# In fact, when I did the calculation with 10 million replicates, I got a p-value of 2e-05.


It is clear from the confidence intervals that beak depth of the offspring of G. fortis parents is more strongly correlated with their offspring than their G. scandens counterparts.
